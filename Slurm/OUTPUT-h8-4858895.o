#########################BEGIN-PROLOG#########################
JobName   = DM_h8
Account   = csc373
NodeList  = cpu-amd-12
Resources = cpu=4,mem=248G,node=1,billing=20
WorkDir   = /deac/csc/classes/csc373/passta23/model_distillation_backup/Slurm
###########################END-PROLOG#########################
→ Epoch 1 done — Avg KL Loss: 2.3114
→ Epoch 2 done — Avg KL Loss: 2.2265
→ Epoch 3 done — Avg KL Loss: 2.1997
→ Epoch 4 done — Avg KL Loss: 2.1760
→ Epoch 5 done — Avg KL Loss: 2.1493
→ Epoch 6 done — Avg KL Loss: 2.1257
→ Epoch 7 done — Avg KL Loss: 2.0741
→ Epoch 8 done — Avg KL Loss: 2.0013
→ Epoch 9 done — Avg KL Loss: 1.9397
→ Epoch 10 done — Avg KL Loss: 1.8093
→ Epoch 11 done — Avg KL Loss: 1.6752
→ Epoch 12 done — Avg KL Loss: 1.5473
→ Epoch 13 done — Avg KL Loss: 1.4181
→ Epoch 14 done — Avg KL Loss: 1.2733
→ Epoch 15 done — Avg KL Loss: 1.1407
→ Epoch 16 done — Avg KL Loss: 1.0032
→ Epoch 17 done — Avg KL Loss: 0.8859
→ Epoch 18 done — Avg KL Loss: 0.7889
→ Epoch 19 done — Avg KL Loss: 0.6923
→ Epoch 20 done — Avg KL Loss: 0.6090
→ Epoch 21 done — Avg KL Loss: 0.5426
→ Epoch 22 done — Avg KL Loss: 0.4800
→ Epoch 23 done — Avg KL Loss: 0.4257
→ Epoch 24 done — Avg KL Loss: 0.3827
→ Epoch 25 done — Avg KL Loss: 0.3511
✅ Distillation finished.
Student model saved to distilled_student_Hidden_Layers_1_epochs_25_hidden_layers_1_temperature_4.0
Distilled model saved to /deac/csc/classes/csc373/passta23/model_distillation_backup/Output/Testing_Results/distilled_student_Hidden_Layers_1_epochs_25_hidden_layers_1_temperature_4.0
Accuracy: 80.00%
Results saved to /deac/csc/classes/csc373/passta23/model_distillation_backup/Output/Testing_Results/distillation_results.csv
